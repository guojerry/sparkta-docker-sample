# sudo -i
# curl -L https://github.com/docker/compose/releases/download/1.5.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
# chmod +x /usr/local/bin/docker-compose
# weave launch-router --dns-domain="demo.stratio.com." --init-peer-count 1 && weave launch-proxy -H tcp://0.0.0.0:12375
# weave expose
# eval $(weave env)

zookeeper:
  image: stratio/zookeeper:3.4.6
  container_name: zookeeper
  ports:
    - "2181:2181"

waitzk:
  image: aanand/wait
  container_name: waitzk
  links:
      - zookeeper

# https://github.com/big-data-europe/demo-spark-sensor-data/blob/master/docker-compose.yml
namenode:
  image: bde2020/hadoop-namenode:1.0.0
  container_name: namenode
  # ports:
  #   - "8020:8020"
  expose:
    - "50070"
  environment:
    CLUSTER_NAME: test
    # CORE_CONF_fs_defaultFS: hdfs://namenode:8020
    # CORE_CONF_hadoop_http_staticuser_user: root
    # HDFS_CONF_dfs_webhdfs_enabled: true
    # HDFS_CONF_dfs_permissions_enabled: false
  env_file:
    - ./hadoop.env

datanode:
  image: bde2020/hadoop-datanode:1.0.0
  # container_name: datanode
  # environment:
    # CORE_CONF_fs_defaultFS: hdfs://namenode:8020
    # CORE_CONF_hadoop_http_staticuser_user: root
    # HDFS_CONF_dfs_webhdfs_enabled: true
    # HDFS_CONF_dfs_permissions_enabled: false
  env_file:
    - ./hadoop.env

# https://hub.docker.com/r/uhopper/hadoop/
# namenode:
#   image: uhopper/hadoop-namenode
#   container_name: namenode
#   ports:
#     - "8020:8020"

# https://github.com/hauptmedia/docker-hdfs-namenode
# namenode:
#   image: hauptmedia/hdfs-namenode
#   container_name: namenode
#   ports:
#     - "8020:8020"

# hadoop:
#   command: /etc/bootstrap.sh -d
#   image: sequenceiq/hadoop-docker:2.6.0
#   container_name: hadoop
#   ports:
#     - "8020:8020"
    # - "9000:9000"

spark-master:
  # image: stratio/spark:1.5.2
  image: stratio/spark:1.6.1
  container_name: spark-master
  environment:
    SPARK_MODE: master
    SPARK_MASTER_PORT: 7077
  ports:
    - "8080:8080"
    # - "7077:7077"
  links:
    - namenode

spark-slave:
  # image: stratio/spark:1.5.2
  image: stratio/spark:1.6.1
  container_name: spark-slave
  environment:
    SPARK_MODE: slave
    SPARK_MASTER_HOST: spark-master.demo.stratio.com
    SPARK_WORKER_CORES: 4
    SPARK_WORKER_MEMORY: 2g
    SPARK_EXECUTOR_MEMORY: 2g
  links:
    - spark-master
    - namenode
  volumes:
    - ./sparkta-kinesis-deps:/opt/sds/jars
    - ./jars:/opt/sds/jarss

spark-slave0:
  # image: stratio/spark:1.5.2
  image: stratio/spark:1.6.1
  container_name: spark-slave0
  environment:
    SPARK_MODE: slave
    SPARK_MASTER_HOST: spark-master.demo.stratio.com
    SPARK_WORKER_CORES: 4
    SPARK_WORKER_MEMORY: 2g
    SPARK_EXECUTOR_MEMORY: 2g
  links:
    - spark-master
    - namenode
  volumes:
    - ./sparkta-kinesis-deps:/opt/sds/jars
    - ./jars:/opt/sds/jarss

spark-slave1:
  # image: stratio/spark:1.5.2
  image: stratio/spark:1.6.1
  container_name: spark-slave1
  environment:
    SPARK_MODE: slave
    SPARK_MASTER_HOST: spark-master.demo.stratio.com
    SPARK_WORKER_CORES: 4
    SPARK_WORKER_MEMORY: 2g
    SPARK_EXECUTOR_MEMORY: 2g
  links:
    - spark-master
    - namenode
  volumes:
    - ./sparkta-kinesis-deps:/opt/sds/jars
    - ./jars:/opt/sds/jarss

sparta:
  image: stratio/sparta:0.9.0
  container_name: sparta
  ports:
    - "9090:9090"
    - "9091:9091"
    # - "8080:8080"
    # - "8020:8020"
  links:
    - waitzk
    - namenode
    # - hadoop
    - spark-master
  environment:
    ZOOKEEPER_HOST: zookeeper.demo.stratio.com
    # SPARK_MASTER: local[8]
    EXECUTION_MODE: standalone
    # SPARK_HOME: /mnt/disk/projects/spark/spark-1.5.2-bin-hadoop2.6
    SPARK_HOME: /opt/sds/spark
    # SPARK_MASTER: local[*]
    # SPARK_MASTER: localhost
    # EXECUTION_MODE: local
    # SPARK_MASTER: 172.18.0.6
    SPARK_MASTER: spark-master.demo.stratio.com
    HDFS_MASTER: namenode
    # SPARK_BINARY_URL: https://www.apache.org/dist/spark/spark-1.6.1/spark-1.6.1-bin-hadoop2.6.tgz
    SPARK_BINARY_URL: http://192.168.0.18:8000/spark-1.6.1-bin-hadoop2.6.tgz
  volumes:
    - ./sparkta-kinesis-deps:/opt/sds/jars
    - ./jars:/opt/sds/jarss
    # - /mnt/disk/projects/spark/sparkta-docker/run:/opt/sds/sparta/bin/run
    - ./docker-entrypoint.sh:/docker-entrypoint.sh
    - ./application.conf:/etc/sds/sparta/application.conf
  # extra_hosts:
  #   - "jpizarro:192.168.0.18"

mongo:
  image: mongo
  container_name: mongo

#eval $(weave env --restore)